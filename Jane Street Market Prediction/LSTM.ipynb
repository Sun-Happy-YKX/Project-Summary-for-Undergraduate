{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datatable as dt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import janestreet\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dt.fread('/kaggle/input/jane-street-market-prediction/train.csv') #用datarable可以加速读取csv文件\n",
    "data = data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reduce Memory Usage by 50%\n",
    "https://www.kaggle.com/tomwarrens/nan-values-depending-on-time-of-day\n",
    "\"\"\"\n",
    "\n",
    "## Reduce Memory\n",
    "\n",
    "def reduce_memory_usage(df):\n",
    "    \n",
    "    start_memory = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe is {start_memory} MB\")\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != 'object':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            \n",
    "            else:\n",
    "#                 reducing float16 for calculating numpy.nanmean\n",
    "#                 if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "#                     df[col] = df[col].astype(np.float16)\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    end_memory = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe after reduction {end_memory} MB\")\n",
    "    print(f\"Reduced by {100 * (start_memory - end_memory) / start_memory} % \")\n",
    "    return df\n",
    "\n",
    "data = reduce_memory_usage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data[(data['weight'] == 0) | (data['date'] <= 85)].index) #删除前85天的数据和weight等于0的数据\n",
    "ignore_columns = ['resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp','ts_id','date']\n",
    "features = [col for col in data.columns if col not in ignore_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(data.mean()) #平均值填充\n",
    "data['action'] = (data['resp'] > 0).astype('int') #resp大于0使action取1，也就是买入\n",
    "data = data.drop(columns=ignore_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timeseries_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset subclass.\n",
    "    Serves as input to DataLoader to transform X\n",
    "      into sequence data using rolling window.\n",
    "    DataLoader using this dataset will output batches\n",
    "      of `(batch_size, seq_len, n_features)` shape.\n",
    "    Suitable as an input to RNNs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, seq_len: int = 32):\n",
    "        self.X = torch.tensor(X).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - (self.seq_len - 1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {'x': torch.tensor(self.X[index:index + self.seq_len], dtype=torch.float),\n",
    "                'y': torch.tensor(self.y[index + self.seq_len - 1], dtype=torch.long)}\n",
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0, c0 = self.init_hidden(x)\n",
    "        out, (hn, cn) = self.rnn(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        return [t.to(device) for t in (h0, c0)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 4096\n",
    "lr = 0.0005\n",
    "input_dim = 131\n",
    "hidden_dim = 256\n",
    "layer_dim = 2\n",
    "output_dim = 2\n",
    "seq_dim = 32\n",
    "target_column = 'action'\n",
    "\n",
    "feature_columns = data.columns[~data.columns.isin([target_column])]\n",
    "train, validation = data[:int(len(data) * 0.8)], data[int(len(data) * 0.2):]  #pandas数据前80%作训练，后20%作预测\n",
    "train_features, train_target = train[feature_columns], train[[target_column]]\n",
    "validation_features, validation_target = validation[feature_columns], validation[[target_column]]\n",
    "train_dataset = Timeseries_Dataset(X=train_features.values, y=train_target.values, seq_len=seq_dim) #转成numpy数据\n",
    "validation_dataset = Timeseries_Dataset(X=validation_features.values, y=validation_target.values, seq_len=seq_dim)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = '/kaggle/input/weight-lstm/best_30.pth' #???\n",
    "\n",
    "phase_training = True\n",
    "if os.path.exists(weight):\n",
    "    phase_training = False\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMClassifier(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "model = model.to(device)\n",
    "if phase_training:\n",
    "    iterations_per_epoch = len(train_loader)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    print('Start model training ...')\n",
    "    best_acc = 0.0\n",
    "    patience, trials = 100, 0\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        for i, train_batch in enumerate(train_loader):\n",
    "            model.train()\n",
    "            features = train_batch['x'].to(device)\n",
    "            targets = train_batch['y'].to(device)\n",
    "            targets = torch.squeeze(targets)\n",
    "            preds = model(features)\n",
    "            loss = criterion(preds, targets) #？？？ok\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch} best model saved with loss: {loss:2.2}')\n",
    "\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        for valid_batch in validation_loader:\n",
    "            features = valid_batch['x'].to(device)\n",
    "            targets = valid_batch['y'].to(device)\n",
    "            targets = torch.squeeze(targets)\n",
    "            preds = model(features)\n",
    "            preds = F.log_softmax(preds, dim=1).argmax(dim=1) #输出结果一行两个特征【0,1】，取出较大的特征对应的列数0或者1作为结果\n",
    "            total += targets.size(0)\n",
    "            correct += (preds == targets).sum().item() #tensor类型转换成python数字\n",
    "\n",
    "        acc = correct / total\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            print(f'Epoch: {epoch:3d}. Loss: {loss.item():.4f}. Acc.: {acc:2.2%}')\n",
    "\n",
    "        if acc > best_acc:\n",
    "            trials = 0\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), 'best.pth') #？？？ok\n",
    "            print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n",
    "        else:\n",
    "            trials += 1\n",
    "            if trials >= patience:\n",
    "                print(f'Early stopping on epoch {epoch}')\n",
    "                break\n",
    "    print('Training Complete !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if phase_training: #???ok\n",
    "    model.load_state_dict(torch.load('best.pth'))\n",
    "else:\n",
    "    model.load_state_dict(torch.load(weight))\n",
    "    \n",
    "model.eval()\n",
    "X_test = None\n",
    "env = janestreet.make_env()\n",
    "env_iter = env.iter_test()\n",
    "for (test_df, pred_df) in tqdm(env_iter):\n",
    "    if test_df['weight'].item() > 0:\n",
    "        test_df = pd.DataFrame(test_df, columns=feature_columns)\n",
    "        test_df = test_df.fillna(test_df.mean())\n",
    "        if X_test is None:\n",
    "            X_test = np.concatenate([test_df for _ in range(seq_dim)],axis=0)\n",
    "        X_test = np.concatenate([X_test[1:], test_df] ,axis=0)\n",
    "        preds = model(torch.tensor(X_test[np.newaxis,:], dtype=torch.float).to(device))\n",
    "        preds = F.log_softmax(preds, dim=1).argmax(dim=1)\n",
    "        action = preds.cpu().detach().numpy()\n",
    "        pred_df.action = action\n",
    "    else:\n",
    "        pred_df.action = 0\n",
    "    env.predict(pred_df)"
   ]
  }
 ]
}